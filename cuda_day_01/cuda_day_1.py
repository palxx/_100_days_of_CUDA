# -*- coding: utf-8 -*-
"""cuda_day_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x3SQtAN-GnQoPbXpaX3ibiBA6KO0uxTQ
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile vector_multiplication.cu

# Commented out IPython magic to ensure Python compatibility.
# %%writefile vector_multiplication.cu
# 
# #include <stdio.h>
# __global__ void multiplyVectors(float *a, float *b, float *c, int n) {
#     int idx = threadIdx.x + blockIdx.x * blockDim.x;
#     if (idx < n) {
#         c[idx] = a[idx] * b[idx];
#     }
# }
# 
# int main() {
#     const int n = 512;
#     float a[n], b[n], c[n];
#     int size = n * sizeof(float);
# 
#     float *dev_a, *dev_b, *dev_c;
#     cudaMalloc((void **)&dev_a, size);
#     cudaMalloc((void **)&dev_b, size);
#     cudaMalloc((void **)&dev_c, size);
# 
#     for (int i = 0; i < n; ++i) {
#         a[i] = b[i] = i;
#     }
# 
#     cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);
#     cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);
# 
#     multiplyVectors<<<2, 256>>>(dev_a, dev_b, dev_c, n);
#     cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);
# 
#     cudaFree(dev_a);
#     cudaFree(dev_b);
#     cudaFree(dev_c);
# 
#     for (int i = 0; i < 10; ++i) {
#         printf("c[%d] = %f\n", i, c[i]);
#     }
#     return 0;
# }

!nvcc vector_multiplication.cu -o vector_multiplication

!./vector_multiplication

!nvidia-smi

#include
__global__ void multiplyVectors(float *a, float *b, float *c, int n) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    if(idx < n) {
        c[idx] = a[idx] * b[idx]
    }
}

int main(){
    cons int n = 512;
    float a[n], b[n], c[n];
    int size = n * sizeof(float);

    float *dev_a, *dev_b, *dev_c;
    cudaMalloc((void **)&dev_a, size);
    cudaMalloc((void **)&dev_b, size);
    cudaMalloc((void **)&dev_c, size);
}